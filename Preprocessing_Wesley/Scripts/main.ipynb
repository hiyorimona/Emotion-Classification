{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wesle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config import Config\n",
    "\n",
    "from affective_text import prepare_affective_text\n",
    "from CARER import load_carer_data\n",
    "from daily_dialog import load_daily_dialog_data\n",
    "from emotion_detection_master import load_emotion_detection_master_data\n",
    "from goemotions import load_goemotion_data\n",
    "from fairy_tails import load_fairy_tail_data\n",
    "from meld_master import load_meld_master_data\n",
    "from ChatGPT import load_gpt_data\n",
    "from Survivor import load_survivor_data\n",
    "from Functions.pre_process import extract_sentiment_nltk, remove_stopwords, apply_stemming, nltk_pos_tag, spacy_ner_tag\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"chatgpt_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../processed_data/\" + folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "else:\n",
    "    print(\"Folder already exists\")\n",
    "    raise FileExistsError(\"Folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectivetext = Config.affectivetext\n",
    "carer = Config.carer\n",
    "chatgpt_generated = Config.chatgpt_generated\n",
    "daily_dialog = Config.daily_dialog\n",
    "emotion_detection_master = Config.emotion_detection_master\n",
    "fairy_tails = Config.fairy_tails\n",
    "goeomotions = Config.goeomotions\n",
    "meld_masters = Config.meld_masters\n",
    "survivor = Config.survivor\n",
    "\n",
    "emotion_column_name = Config.emotion_colm_name\n",
    "happiness_other = Config.happiness_other\n",
    "extract_sentiment = Config.extract_sentiment\n",
    "get_positive = Config.get_positive\n",
    "get_highest = Config.get_highest\n",
    "\n",
    "sentiment_colmn_name = Config.sentiment_colmn_name\n",
    "sentiment_library = Config.sentiment_library\n",
    "keep_only_compound = Config.keep_only_compound\n",
    "remove_stopword = Config.remove_stopwords\n",
    "stemmer = Config.stemmer\n",
    "\n",
    "NER_extraction = Config.NER_extraction\n",
    "NER_colmn_name = Config.NER_colmn_name\n",
    "\n",
    "POS_extraction = Config.POS_extraction\n",
    "POS_colmn_name = Config.POS_colmn_name\n",
    "\n",
    "priotize_happy = Config.priotize_happy\n",
    "\n",
    "evenly_distributed = Config.evenly_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "dataset_used = \"\"\n",
    "text_prioritize_happy = \"\"\n",
    "if affectivetext:\n",
    "    affective_df = prepare_affective_text()\n",
    "    final_df = pd.concat([final_df, affective_df], ignore_index=True)\n",
    "    dataset_used += \"- Affective Text \\n\"\n",
    "\n",
    "if carer:\n",
    "    carer_df = load_carer_data()\n",
    "    final_df = pd.concat([final_df, carer_df], ignore_index=True)\n",
    "    dataset_used += \"- Carer \\n\"\n",
    "\n",
    "if daily_dialog:\n",
    "    daily_dialog_df = load_daily_dialog_data()\n",
    "    final_df = pd.concat([final_df, daily_dialog_df], ignore_index=True)\n",
    "    dataset_used += \"- Daily Dialog \\n\"\n",
    "\n",
    "if emotion_detection_master: \n",
    "    emotion_detection_master_df = load_emotion_detection_master_data()\n",
    "    final_df = pd.concat([final_df, emotion_detection_master_df], ignore_index=True)\n",
    "    dataset_used += \"- Emotion Detection Master \\n\"\n",
    "\n",
    "\n",
    "if goeomotions:\n",
    "    goemotions_df = load_goemotion_data()\n",
    "    final_df = pd.concat([final_df, goemotions_df], ignore_index=True)\n",
    "    dataset_used += \"- Goemotions \\n\"\n",
    "    if priotize_happy:\n",
    "        text_prioritize_happy = \"\"\"\n",
    "### GoEmotions\n",
    "Sentences with multiple emotions where one of them is happiness, are prioritized to have happy emotion. \\n\"\"\"\n",
    "    else:\n",
    "        text_prioritize_happy = \" \"\n",
    "\n",
    "if fairy_tails:\n",
    "    fairy_tail_df = load_fairy_tail_data()\n",
    "    final_df = pd.concat([final_df, fairy_tail_df], ignore_index=True)\n",
    "    dataset_used += \"- Fairy Tails \\n\"\n",
    "\n",
    "if meld_masters:\n",
    "    meld_master_df = load_meld_master_data()\n",
    "    final_df = pd.concat([final_df, meld_master_df], ignore_index=True)\n",
    "    dataset_used += \"- Meld Masters \\n\"\n",
    "\n",
    "if chatgpt_generated:\n",
    "    gpt_df = load_gpt_data()\n",
    "    final_df = pd.concat([final_df, gpt_df], ignore_index=True)\n",
    "    dataset_used += \"- ChatGPT \\n\"\n",
    "\n",
    "if survivor:\n",
    "    survivor_df = load_survivor_data()\n",
    "    final_df = pd.concat([final_df, survivor_df], ignore_index=True)\n",
    "    dataset_used += \"- Survivor \\n\"\n",
    "\n",
    "\n",
    "\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.copy()\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Sad', Config.sad)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Happy', Config.happy)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Mad', Config.mad)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Surprised', Config.surpised)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Disgusted', Config.disgusted)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Disgust', Config.disgusted)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('fear', Config.scared)\n",
    "final_df[emotion_column_name] = final_df[emotion_column_name].replace('Scared', Config.scared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happiness', 'sadness', 'anger', 'surprise', 'scared', 'disgust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[emotion_column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "disgust      21089\n",
       "anger        11823\n",
       "happiness     1901\n",
       "sadness       1901\n",
       "surprise      1901\n",
       "scared        1901\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if evenly_distributed:\n",
    "    minimum = final_df[emotion_column_name].value_counts().min()\n",
    "    for x in final_df[emotion_column_name].unique():\n",
    "        num_to_drop = final_df[final_df[emotion_column_name] == x].shape[0] - minimum\n",
    "        drop_indices = final_df[final_df[emotion_column_name] == x].sample(num_to_drop, random_state=1).index\n",
    "        final_df = final_df.drop(drop_indices)\n",
    "    text_evenly_distributed = \"Emotions have been evenly distributed by randomly removing rows until all emotions have the same amount. \\n\"  \n",
    "else:\n",
    "    text_evenly_distributed = \"Emotions have not been evenly distributed \\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "disgust      21089\n",
       "anger        11823\n",
       "happiness     1901\n",
       "sadness       1901\n",
       "surprise      1901\n",
       "scared        1901\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_senti = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if happiness_other:\n",
    "    print(\"Changing the emotion column to happiness and other\")\n",
    "    final_df['emotion'] = final_df['emotion'].apply(lambda x: 'other' if x != 'happiness' else 'happiness')\n",
    "\n",
    "if remove_stopword:\n",
    "    print(\"Removing the stopwords\")\n",
    "    final_df['sentence'] = final_df['sentence'].progress_apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "if extract_sentiment:\n",
    "    print(\"Extracting the sentiment\")\n",
    "    if sentiment_library == 'nltk':\n",
    "        final_df[sentiment_colmn_name] = final_df['sentence'].progress_apply(lambda x: extract_sentiment_nltk(x, keep_only_compound=keep_only_compound, get_positive=get_positive, get_highest=get_highest))\n",
    "        text_senti = \"Sentiment is using NLTK\"\n",
    "\n",
    "    \n",
    "if NER_extraction:\n",
    "    print(\"Extracting the NER tags\")\n",
    "    final_df[NER_colmn_name] = final_df['sentence'].progress_apply(lambda x: spacy_ner_tag(x))\n",
    "\n",
    "if POS_extraction:\n",
    "    print(\"Extracting the POS tags\")\n",
    "    final_df[POS_colmn_name] = final_df['sentence'].progress_apply(lambda x: nltk_pos_tag(x))\n",
    "\n",
    "if stemmer:\n",
    "    print(\"Applying the stemming\")\n",
    "    final_df['sentence'] = final_df['sentence'].progress_apply(lambda x: apply_stemming(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I feel overjoyed and filled with warmth knowin...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Her tears mingled with the rain as she stood a...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't believe you would betray my trust like...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sound of footsteps approaching in the dark...</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40511</th>\n",
       "      <td>The mere thought of their presence makes my sk...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40512</th>\n",
       "      <td>I find myself creating excuses to keep a dista...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40513</th>\n",
       "      <td>The carefully planned itinerary was suddenly w...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40514</th>\n",
       "      <td>The feeling weighs heavy like a dark cloud han...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40515</th>\n",
       "      <td>I cannot believe such blatant disrespect and d...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40516 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence    emotion\n",
       "0      I feel overjoyed and filled with warmth knowin...  happiness\n",
       "1      Her tears mingled with the rain as she stood a...    sadness\n",
       "2      I can't believe you would betray my trust like...      anger\n",
       "3                                    I can't believe it!   surprise\n",
       "4      The sound of footsteps approaching in the dark...     scared\n",
       "...                                                  ...        ...\n",
       "40511  The mere thought of their presence makes my sk...    disgust\n",
       "40512  I find myself creating excuses to keep a dista...    disgust\n",
       "40513  The carefully planned itinerary was suddenly w...    disgust\n",
       "40514  The feeling weighs heavy like a dark cloud han...    disgust\n",
       "40515  I cannot believe such blatant disrespect and d...    disgust\n",
       "\n",
       "[40516 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_unique_values = \"\"\n",
    "i = 0\n",
    "for x in final_df[emotion_column_name].value_counts().index:\n",
    "    text_unique_values += f\"- {x}\"\n",
    "    text_unique_values += f\"({final_df[emotion_column_name].value_counts().iloc[i]})\\n\"\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- disgust(21089)\\n- anger(11823)\\n- happiness(1901)\\n- sadness(1901)\\n- surprise(1901)\\n- scared(1901)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_text = f\"\"\"\n",
    "### In this folder a dataset is present, with the following 'settings'/ filters / features applied:\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "Dataset name: {folder_name}\n",
    "\n",
    "Datasets used:\n",
    "\n",
    "{dataset_used}\n",
    "\n",
    "\n",
    "Name of the emotion column: {emotion_column_name}\n",
    "\n",
    "\n",
    "Which emotions does it contain: \n",
    "\n",
    "{text_unique_values}\n",
    "\n",
    "\n",
    "## Preprocessing steps\n",
    "\n",
    "Remove neutral emotions: __{happiness_other}__\n",
    "\n",
    "Removed stopwords: __{remove_stopword}__\n",
    "\n",
    "Extracted sentiment: __{extract_sentiment}__\n",
    "\n",
    "Extracted NER tags: __{NER_extraction}__\n",
    "\n",
    "Extracted POS tags: __{POS_extraction}__\n",
    "\n",
    "{text_senti}\n",
    "\n",
    "Applied stemming: __{stemmer}__\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "Number of rows: __{final_df.shape[0]}__\n",
    "\n",
    "\n",
    "Number of columns: __{final_df.shape[1]}__\n",
    "\n",
    "Compressed: __Zip__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{final_df[\"emotion\"].value_counts()}\n",
    "\n",
    "\n",
    "\n",
    "## Dataset Preview\n",
    "{final_df.head(5).to_markdown()}\n",
    "\n",
    "\n",
    "{text_prioritize_happy}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + '/README.md', 'w') as readme_file:\n",
    "    readme_file.write(readme_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"../processed_data/{folder}/dataset.csv\", index=False, compression='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
